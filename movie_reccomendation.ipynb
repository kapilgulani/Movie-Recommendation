{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.25.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kapil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\kapil\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\AppData\\Local\\Temp\\ipykernel_53280\\1838691772.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movies data\n",
    "movies_df = pd.read_csv('C:/Users/kapil/Downloads/ml-25m/movies.csv', usecols=['movieId', 'title'], dtype={'movieId': 'int32', 'title': 'str'})\n",
    "# Load ratings data\n",
    "ratings_df = pd.read_csv('C:/Users/kapil/Downloads/ml-25m/ratings.csv', usecols=['userId', 'movieId', 'rating'], dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: (25000095, 3)\n",
      "Size after dropping duplicates: (25000095, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original size: {ratings_df.shape}\")\n",
    "ratings_df = ratings_df.drop_duplicates(subset=['userId', 'movieId'])\n",
    "print(f\"Size after dropping duplicates: {ratings_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       int32\n",
      "movieId      int32\n",
      "rating     float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       1      296     5.0\n",
      "1       1      306     3.5\n",
      "2       1      307     5.0\n",
      "3       1      665     5.0\n",
      "4       1      899     3.5\n",
      "userId     0\n",
      "movieId    0\n",
      "rating     0\n",
      "dtype: int64\n",
      "             userId       movieId        rating\n",
      "count  2.500010e+07  2.500010e+07  2.500010e+07\n",
      "mean   8.118928e+04  2.138798e+04  3.533855e+00\n",
      "std    4.679172e+04  3.919886e+04  1.060744e+00\n",
      "min    1.000000e+00  1.000000e+00  5.000000e-01\n",
      "25%    4.051000e+04  1.196000e+03  3.000000e+00\n",
      "50%    8.091400e+04  2.947000e+03  3.500000e+00\n",
      "75%    1.215570e+05  8.623000e+03  4.000000e+00\n",
      "max    1.625410e+05  2.091710e+05  5.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(ratings_df.head())\n",
    "\n",
    "# Check for any NaN values which might cause issues\n",
    "print(ratings_df.isnull().sum())\n",
    "\n",
    "# Summary statistics for numerical columns to identify any anomalies\n",
    "print(ratings_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\reshape.py:143: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  num_cells = num_rows * num_columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: index 1007624404 is out of bounds for axis 0 with size 1007623835\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt a simple pivot without fill_value to see if it works\n",
    "    simple_matrix = ratings_df.pivot_table(index='movieId', columns='userId', values='rating')\n",
    "    print(simple_matrix.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate (movieId, userId) pairs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate (movieId, userId) pairs\n",
    "duplicates = ratings_df.duplicated(subset=['movieId', 'userId']).sum()\n",
    "print(f\"Duplicate (movieId, userId) pairs: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId   132     243     264     653     660     752     997     1156    \\\n",
      "movieId                                                                   \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "10          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "14          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "16          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "userId   1173    1456    ...  161277  161374  161470  161657  161658  161725  \\\n",
      "movieId                  ...                                                   \n",
      "1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "10          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "14          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "16          0.0     0.0  ...     3.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "userId   161872  161969  162024  162210  \n",
      "movieId                                  \n",
      "1           0.0     0.0     0.0     0.0  \n",
      "2           0.0     0.0     0.0     0.0  \n",
      "10          0.0     0.0     0.0     0.0  \n",
      "14          0.0     0.0     0.0     0.0  \n",
      "16          0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 986 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use a smaller subset of the DataFrame\n",
    "small_df = ratings_df.sample(n=1000)  # Adjust n as needed based on your system's capabilities\n",
    "try:\n",
    "    small_matrix = small_df.pivot_table(index='movieId', columns='userId', values='rating', fill_value=0)\n",
    "    print(small_matrix.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error with smaller subset: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId     1    2\n",
      "movieId          \n",
      "1        4.0  2.0\n",
      "2        5.0  3.0\n",
      "3        3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# Example with made-up data\n",
    "df_test = pd.DataFrame({\n",
    "    'movieId': [1, 2, 3, 1, 2, 3],\n",
    "    'userId': [1, 1, 1, 2, 2, 2],\n",
    "    'rating': [4, 5, 3, 2, 3, 4]\n",
    "})\n",
    "\n",
    "try:\n",
    "    matrix_test = df_test.pivot_table(index='movieId', columns='userId', values='rating', aggfunc='mean').fillna(0)\n",
    "    print(matrix_test)\n",
    "except Exception as e:\n",
    "    print(f\"Test Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Ensure userId and movieId are sequential integers starting from 0\n",
    "# This step is necessary because scipy's sparse matrix constructors expect zero-indexed integers\n",
    "user_ids = ratings_df['userId'].astype(\"category\").cat.codes\n",
    "movie_ids = ratings_df['movieId'].astype(\"category\").cat.codes\n",
    "\n",
    "# Number of users and movies\n",
    "num_users = user_ids.nunique()\n",
    "num_movies = movie_ids.nunique()\n",
    "\n",
    "# Create a sparse matrix\n",
    "ratings_matrix_sparse = csr_matrix((ratings_df['rating'], (movie_ids, user_ids)), shape=(num_movies, num_users))\n",
    "\n",
    "# If you need to work with a dense matrix (e.g., for certain types of analyses), you can convert it back:\n",
    "# Be cautious with this step if your dataset is large, as it can consume a lot of memory\n",
    "ratings_matrix_dense = ratings_matrix_sparse.todense()\n",
    "\n",
    "# Note: The dense matrix will have movies as rows and users as columns, with ratings as values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity between movies\n",
    "# Note: cosine_similarity expects a dense matrix, but it can handle sparse matrices efficiently\n",
    "movie_similarity = cosine_similarity(ratings_matrix_sparse, dense_output=False)\n",
    "\n",
    "# movie_similarity is now a sparse matrix of shape (num_movies, num_movies) containing the cosine similarity between movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended: ['Star Wars: Episode IV - A New Hope (1977)', 'Toy Story 2 (1999)', 'Back to the Future (1985)', 'Forrest Gump (1994)', 'Jurassic Park (1993)']\n"
     ]
    }
   ],
   "source": [
    "def get_movie_title(movie_id, movies_df):\n",
    "    \"\"\"Helper function to get movie title by movieId\"\"\"\n",
    "    return movies_df[movies_df['movieId'] == movie_id]['title'].iloc[0]\n",
    "\n",
    "def recommend_movies(movie_id, movies_df, movie_similarity, k=10):\n",
    "    \"\"\"\n",
    "    Recommends movies based on a given movie ID.\n",
    "    \n",
    "    Parameters:\n",
    "    - movie_id: The ID of the movie for which to find similar movies.\n",
    "    - movies_df: DataFrame containing movie IDs and titles.\n",
    "    - movie_similarity: Sparse matrix containing cosine similarity between movies.\n",
    "    - k: Number of top similar movies to return.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of movie titles recommended for the user.\n",
    "    \"\"\"\n",
    "    # Convert movie_id to the zero-based index used in the similarity matrix\n",
    "    movie_idx = movies_df.index[movies_df['movieId'] == movie_id].tolist()[0]\n",
    "    \n",
    "    # Get similarity values with other movies\n",
    "    # Since movie_similarity is a sparse matrix, toarray() will convert it to a dense format\n",
    "    similarity_scores = movie_similarity[movie_idx].toarray().flatten()\n",
    "    \n",
    "    # Sort the movies based on similarity scores\n",
    "    # [::-1] to sort in descending order, and [1:k+1] to skip the first movie (itself)\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:k+1]\n",
    "    \n",
    "    # Convert back to movie IDs\n",
    "    similar_movie_ids = movies_df.iloc[similar_indices]['movieId'].tolist()\n",
    "    \n",
    "    # Get movie titles\n",
    "    similar_movies = [get_movie_title(id, movies_df) for id in similar_movie_ids]\n",
    "    \n",
    "    return similar_movies\n",
    "\n",
    "# Example usage (assuming you have a movie_id and movies_df prepared)\n",
    "movie_id = 1  # Toy Story; change this to a valid movieId from your dataset\n",
    "recommended_movies = recommend_movies(movie_id, movies_df, movie_similarity, k=5)\n",
    "print(\"Movies recommended:\", recommended_movies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
